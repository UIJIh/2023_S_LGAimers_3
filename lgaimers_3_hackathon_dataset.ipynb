{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b555e43",
   "metadata": {},
   "source": [
    "# Dataset Info.\n",
    "\n",
    "## 1. train.csv\n",
    "ID : 실제 판매되고 있는 고유 ID<br>\n",
    "제품 : 제품 코드<br>\n",
    "대분류 : 제품의 대분류 코드<br>\n",
    "중분류 : 제품의 중분류 코드<br>\n",
    "소분류 : 제품의 소분류 코드<br>\n",
    "브랜드 : 제품의 브랜드 코드<br>\n",
    "2022-01-01 ~ 2023-04-04 : 실제 일별 판매량<br>\n",
    "단, 제품이 동일하여도 판매되고 있는 고유 ID 별로 기재한 분류 정보가 상이할 수 있음<br>\n",
    "즉 고유 ID가 다르다면, 제품이 같더라도 다른 판매 채널<br><br>\n",
    "\n",
    "\n",
    "## 2. sample_submission.csv -제출 양식\n",
    "ID : 실제 판매되고 있는 고유 ID<br>\n",
    "\t\t\t\t\t\t※ 제출 시 ID Column에 해당하는 데이터에 반드시 zfill(5)를 적용할 필요 없음<br>\n",
    "\n",
    "2023-04-05 ~ 2023-04-25 : 예측한 일별 판매량<br>\n",
    "\n",
    "\n",
    "## 3. sales.csv [파일] - 메타(Meta) 정보\n",
    "ID : 실제 판매되고 있는 고유 ID<br>\n",
    "제품 : 제품 코드<br>\n",
    "대분류 : 제품의 대분류 코드<br>\n",
    "중분류 : 제품의 중분류 코드<br>\n",
    "소분류 : 제품의 소분류 코드<br>\n",
    "브랜드 : 제품의 브랜드 코드<br>\n",
    "2022-01-01 ~ 2023-04-04 : 실제 일별 총 판매금액<br>\n",
    "단, 제품이 동일하여도 판매되고 있는 고유 ID 별로 기재한 분류 정보가 상이할 수 있음<br>\n",
    "즉 고유 ID가 다르다면, 제품이 같더라도 다른 판매 채널<br><br>\n",
    "\n",
    "\n",
    "## 4. brand_keyword_cnt.csv [파일] - 메타(Meta) 정보\n",
    "브랜드 : 브랜드 코드<br>\n",
    "2022-01-01 ~ 2023-04-04 : 브랜드의 연관키워드 언급량을 정규화한 일별 데이터<br><br>\n",
    "\n",
    "\n",
    "## 5. product_info.csv [파일] - 메타(Meta) 정보\n",
    "제품 : 제품 코드<br>\n",
    "제품특성 : 제품 특성 데이터(Text)<br>\n",
    "train.csv에 존재하는 모든 제품 코드가 포함되어 있지 않음. 또는 product_info.csv에 존재하는 제품 코드가 train.csv에 존재하지 않을 수 있음<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d65efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'brand_keyword_cnt.csv', 'lgaimers_3_hackathon_dataset.ipynb', 'product_info.csv', 'sales.csv', 'sample_submission.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a701f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c1a8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제품</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-01-02</th>\n",
       "      <th>2022-01-03</th>\n",
       "      <th>2022-01-04</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-26</th>\n",
       "      <th>2023-03-27</th>\n",
       "      <th>2023-03-28</th>\n",
       "      <th>2023-03-29</th>\n",
       "      <th>2023-03-30</th>\n",
       "      <th>2023-03-31</th>\n",
       "      <th>2023-04-01</th>\n",
       "      <th>2023-04-02</th>\n",
       "      <th>2023-04-03</th>\n",
       "      <th>2023-04-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-00001-00001</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B002-00002-00001</td>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B002-00002-00002</td>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B002-00002-00003</td>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B002-00003-00001</td>\n",
       "      <td>B002-C001-0001</td>\n",
       "      <td>B002-C002-0001</td>\n",
       "      <td>B002-C003-0003</td>\n",
       "      <td>B002-00003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                제품             대분류             중분류             소분류  \\\n",
       "0   0  B002-00001-00001  B002-C001-0002  B002-C002-0007  B002-C003-0038   \n",
       "1   1  B002-00002-00001  B002-C001-0003  B002-C002-0008  B002-C003-0044   \n",
       "2   2  B002-00002-00002  B002-C001-0003  B002-C002-0008  B002-C003-0044   \n",
       "3   3  B002-00002-00003  B002-C001-0003  B002-C002-0008  B002-C003-0044   \n",
       "4   4  B002-00003-00001  B002-C001-0001  B002-C002-0001  B002-C003-0003   \n",
       "\n",
       "          브랜드  2022-01-01  2022-01-02  2022-01-03  2022-01-04  ...  \\\n",
       "0  B002-00001           0           0           0           0  ...   \n",
       "1  B002-00002           0           0           0           0  ...   \n",
       "2  B002-00002           0           0           0           0  ...   \n",
       "3  B002-00002           0           0           0           0  ...   \n",
       "4  B002-00003           0           0           0           0  ...   \n",
       "\n",
       "   2023-03-26  2023-03-27  2023-03-28  2023-03-29  2023-03-30  2023-03-31  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           1           3           2   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   2023-04-01  2023-04-02  2023-04-03  2023-04-04  \n",
       "0           0           0           0           0  \n",
       "1           0           0           2           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 465 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./train.csv')   # datetime 형태로\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e1738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 구조는: (15890, 465)\n",
      "데이터 타입은: ID             int64\n",
      "제품            object\n",
      "대분류           object\n",
      "중분류           object\n",
      "소분류           object\n",
      "               ...  \n",
      "2023-03-31     int64\n",
      "2023-04-01     int64\n",
      "2023-04-02     int64\n",
      "2023-04-03     int64\n",
      "2023-04-04     int64\n",
      "Length: 465, dtype: object\n",
      "데이터 칼럼은: Index(['ID', '제품', '대분류', '중분류', '소분류', '브랜드', '2022-01-01', '2022-01-02',\n",
      "       '2022-01-03', '2022-01-04',\n",
      "       ...\n",
      "       '2023-03-26', '2023-03-27', '2023-03-28', '2023-03-29', '2023-03-30',\n",
      "       '2023-03-31', '2023-04-01', '2023-04-02', '2023-04-03', '2023-04-04'],\n",
      "      dtype='object', length=465)\n"
     ]
    }
   ],
   "source": [
    "print('데이터 구조는:', df.shape)\n",
    "print('데이터 타입은:', df.dtypes)\n",
    "print('데이터 칼럼은:', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134221ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 날짜 열들을 날짜/시간 데이터 타입으로 변환\u001b[39;00m\n\u001b[0;32m      6\u001b[0m date_columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m6\u001b[39m:]  \u001b[38;5;66;03m# 날짜 열들의 이름을 가져옴\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[date_columns] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ID 열을 인덱스로 설정\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Neuer Ordner\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1071\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n\u001b[1;32m-> 1071\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[0;32m   1073\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "File \u001b[1;32mC:\\Neuer Ordner\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1186\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, tz)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(req):\n\u001b[0;32m   1185\u001b[0m     _required \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(req)\n\u001b[1;32m-> 1186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto assemble mappings requires at least that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[year, month, day] be specified: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_required\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1189\u001b[0m     )\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# keys we don't recognize\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m excess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(unit_rev\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(_unit_map\u001b[38;5;241m.\u001b[39mvalues()))\n",
      "\u001b[1;31mValueError\u001b[0m: to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 날짜 열들을 날짜/시간 데이터 타입으로 변환\n",
    "date_columns = df.columns[6:]  # 날짜 열들의 이름을 가져옴\n",
    "df[date_columns] = pd.to_datetime(df[date_columns], format='%Y-%m-%d', dayfirst=False)\n",
    "\n",
    "# ID 열을 인덱스로 설정\n",
    "df.set_index('ID', inplace=True)\n",
    "\n",
    "# 시계열 데이터 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=df[date_columns])\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Data Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9974ed8",
   "metadata": {},
   "source": [
    "## 결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8047acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.sum of           ID     제품    대분류    중분류    소분류    브랜드  2022-01-01  2022-01-02  \\\n",
       "0      False  False  False  False  False  False       False       False   \n",
       "1      False  False  False  False  False  False       False       False   \n",
       "2      False  False  False  False  False  False       False       False   \n",
       "3      False  False  False  False  False  False       False       False   \n",
       "4      False  False  False  False  False  False       False       False   \n",
       "...      ...    ...    ...    ...    ...    ...         ...         ...   \n",
       "15885  False  False  False  False  False  False       False       False   \n",
       "15886  False  False  False  False  False  False       False       False   \n",
       "15887  False  False  False  False  False  False       False       False   \n",
       "15888  False  False  False  False  False  False       False       False   \n",
       "15889  False  False  False  False  False  False       False       False   \n",
       "\n",
       "       2022-01-03  2022-01-04  ...  2023-03-26  2023-03-27  2023-03-28  \\\n",
       "0           False       False  ...       False       False       False   \n",
       "1           False       False  ...       False       False       False   \n",
       "2           False       False  ...       False       False       False   \n",
       "3           False       False  ...       False       False       False   \n",
       "4           False       False  ...       False       False       False   \n",
       "...           ...         ...  ...         ...         ...         ...   \n",
       "15885       False       False  ...       False       False       False   \n",
       "15886       False       False  ...       False       False       False   \n",
       "15887       False       False  ...       False       False       False   \n",
       "15888       False       False  ...       False       False       False   \n",
       "15889       False       False  ...       False       False       False   \n",
       "\n",
       "       2023-03-29  2023-03-30  2023-03-31  2023-04-01  2023-04-02  2023-04-03  \\\n",
       "0           False       False       False       False       False       False   \n",
       "1           False       False       False       False       False       False   \n",
       "2           False       False       False       False       False       False   \n",
       "3           False       False       False       False       False       False   \n",
       "4           False       False       False       False       False       False   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "15885       False       False       False       False       False       False   \n",
       "15886       False       False       False       False       False       False   \n",
       "15887       False       False       False       False       False       False   \n",
       "15888       False       False       False       False       False       False   \n",
       "15889       False       False       False       False       False       False   \n",
       "\n",
       "       2023-04-04  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "...           ...  \n",
       "15885       False  \n",
       "15886       False  \n",
       "15887       False  \n",
       "15888       False  \n",
       "15889       False  \n",
       "\n",
       "[15890 rows x 465 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c081e312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# 데이터프레임 df에서 결측치 시각화\n",
    "msno.matrix(df)\n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ce8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':90, # 90일치로 학습\n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':10, # 반복\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':1096, # 데이터 묶음\n",
    "    'SEED':41\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b40ac",
   "metadata": {},
   "source": [
    "무작위성을 제어하기 위해 여러 라이브러리의 시드(seed)를 설정하는 함수를 정의하고, 해당 시드로 무작위성을 고정시키는 코드입니다. 이를 통해 코드 실행 시마다 동일한 결과를 얻을 수 있습니다. 이러한 작업은 실험 재현성을 위해 중요합니다.\n",
    "\n",
    "여기서 사용된 함수와 해당 함수 내용에 대한 설명은 다음과 같습니다:\n",
    "\n",
    "1. **seed_everything(seed)**: 이 함수는 시드(seed)를 입력으로 받아서 여러 라이브러리의 시드를 설정하는 역할을 합니다. 이 함수를 호출하여 시드를 설정하면 코드 실행 시의 난수 생성이 일관된 결과를 보이게 됩니다.\n",
    "\n",
    "2. **random.seed(seed)**: 파이썬의 기본 랜덤 모듈인 `random`의 시드를 설정합니다. 이로써 파이썬의 내장 랜덤 함수가 동일한 순서로 결과를 생성하게 됩니다.\n",
    "\n",
    "3. **os.environ['PYTHONHASHSEED'] = str(seed)**: 파이썬 내장 해시 함수와 관련된 시드를 설정합니다. 해시 함수에도 시드를 적용하여 해시 값의 순서를 일관성 있게 만듭니다.\n",
    "\n",
    "4. **np.random.seed(seed)**: NumPy의 난수 생성 함수의 시드를 설정합니다. NumPy를 사용하는 랜덤 연산에도 시드가 영향을 줍니다.\n",
    "\n",
    "5. **torch.manual_seed(seed)**: PyTorch의 난수 생성 함수의 시드를 설정합니다. 파이토치 내에서의 랜덤성에 영향을 미칩니다.\n",
    "\n",
    "6. **torch.cuda.manual_seed(seed)**: CUDA(GPU)를 사용하는 경우, 해당 GPU의 난수 생성 함수의 시드를 설정합니다.\n",
    "\n",
    "7. **torch.backends.cudnn.deterministic = True**: CUDA 연산을 위한 cuDNN 라이브러리에서 무작위성을 완전히 제거하여, 동일한 입력에 대해 동일한 결과를 보장합니다. 단, 이로 인해 일부 성능 저하가 발생할 수 있습니다.\n",
    "\n",
    "8. **torch.backends.cudnn.benchmark = True**: cuDNN 라이브러리의 동적 벤치마크 모드를 활성화합니다. 이 모드에서는 입력 크기에 따라 최적의 연산을 선택하여 속도를 높일 수 있지만, 일관된 결과를 보장하지 않습니다. 실험 재현성을 위해서는 비활성화하는 것이 좋습니다.\n",
    "\n",
    "마지막으로 `seed_everything(CFG['SEED'])`라인은 코드의 `CFG` 딕셔너리에서 `'SEED'` 키에 저장된 시드 값을 가져와서 위에서 정의한 함수를 통해 무작위성을 고정시키는 역할을 합니다. 이를 통해 동일한 시드로 코드를 실행하면 항상 동일한 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4c6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ed1ea",
   "metadata": {},
   "source": [
    "## MinMax Scaling\n",
    "- 데이터를 정해진 범위 내로 변환하는 데이터 스케일링 기법 중 하나입니다. 주어진 데이터의 최솟값과 최댓값을 사용하여 데이터를 새로운 범위로 변환하므로, 모든 데이터가 일정한 범위 내에 들도록 조정됩니다.\n",
    "- 이러한 스케일링은 다양한 머신러닝 알고리즘에서 데이터의 분포를 조정하거나, 특정 feature의 영향력을 균등하게 만들기 위해 사용됩니다.\n",
    "\n",
    "MinMax Scaling의 수식은 다음과 같습니다:\n",
    "\n",
    "$$\n",
    "X_{\\text{new}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$$\n",
    "\n",
    "여기서,\n",
    "- $X_{\\text{new}}$는 스케일링된 새로운 값\n",
    "- $X$는 원본 데이터 값\n",
    "- $X_{\\text{min}}$은 해당 feature의 최솟값\n",
    "- $X_{\\text{max}}$은 해당 feature의 최댓값\n",
    "\n",
    "이렇게 스케일링을 수행하면 모든 데이터는 0과 1 사이의 범위에 위치하게 됩니다. 하지만 주의할 점은 MinMax Scaling은 이상치(outliers)에 민감할 수 있어서 이상치가 있는 데이터에서는 오히려 스케일링 결과가 왜곡될 수 있습니다.\n",
    "\n",
    "Min-Max Scaling은 정해진 범위 내에서 데이터를 조정할 수 있으므로, 다양한 데이터를 일정한 범위로 조정하여 학습 알고리즘의 성능을 개선하거나 특정 feature의 영향을 균등하게 만드는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bc95e",
   "metadata": {},
   "source": [
    "숫자형 변수들을 min-max scaling으로 스케일링하는 작업을 수행하는 코드입니다. 이 코드를 통해 데이터의 값을 일정 범위로 조정하여 모델 학습을 개선하거나, 데이터의 분포를 조절하는 등의 효과를 얻을 수 있습니다.\n",
    "\n",
    "아래는 코드의 각 부분에 대한 설명입니다:\n",
    "\n",
    "1. **numeric_cols = train_data.columns[4:]**: `train_data`의 열 중 4번 인덱스부터 끝까지가 숫자형 변수임을 가정하고 해당 열들을 `numeric_cols`에 할당합니다.\n",
    "\n",
    "2. **min_values = train_data[numeric_cols].min(axis=1)**: 각 행별로 숫자형 변수들의 최소값을 계산하여 `min_values`에 저장합니다.\n",
    "\n",
    "3. **max_values = train_data[numeric_cols].max(axis=1)**: 각 행별로 숫자형 변수들의 최대값을 계산하여 `max_values`에 저장합니다.\n",
    "\n",
    "4. **ranges = max_values - min_values**: 각 행별로 변수들의 범위를 계산합니다.\n",
    "\n",
    "5. **ranges[ranges == 0] = 1**: 범위가 0인 경우, 1로 대체하여 나누기 연산 시 분모가 0이 되는 것을 방지합니다. 이는 값들이 동일한 경우에 해당합니다.\n",
    "\n",
    "6. **train_data[numeric_cols] = ...**: 데이터프레임 `train_data`의 숫자형 변수들에 대해 min-max scaling을 수행합니다. 각 변수의 값에서 최소값을 뺀 후, 계산한 범위로 나눠서 값을 0과 1 사이의 범위로 조정합니다.\n",
    "\n",
    "7. **scale_min_dict = min_values.to_dict()** 및 **scale_max_dict = max_values.to_dict()**: min-max scaling에 사용된 각 변수의 최소값과 최대값을 각각 딕셔너리 형태로 저장합니다. 이후에 테스트 데이터나 새로운 데이터를 스케일링할 때 사용할 수 있습니다.\n",
    "\n",
    "이 코드는 데이터의 값을 일정 범위로 조정하여 모델 학습에 도움이 될 수 있으며, 스케일링된 데이터와 관련된 정보를 저장하여 추후에 재사용할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd78b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train.csv').drop(columns=['ID', '제품'])\n",
    "\n",
    "# Data Scaling\n",
    "# 숫자형 변수들의 min-max scaling을 수행하는 코드입니다.\n",
    "numeric_cols = train_data.columns[4:]\n",
    "# 칵 column의 min 및 max 계산\n",
    "min_values = train_data[numeric_cols].min(axis=1)\n",
    "max_values = train_data[numeric_cols].max(axis=1)\n",
    "# 각 행의 범위(max-min)를 계산하고, 범위가 0인 경우 1로 대체\n",
    "ranges = max_values - min_values\n",
    "ranges[ranges == 0] = 1\n",
    "# min-max scaling 수행\n",
    "train_data[numeric_cols] = (train_data[numeric_cols].subtract(min_values, axis=0)).div(ranges, axis=0)\n",
    "# max와 min 값을 dictionary 형태로 저장\n",
    "scale_min_dict = min_values.to_dict()\n",
    "scale_max_dict = max_values.to_dict()\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(train_data[col])\n",
    "    train_data[col] = label_encoder.transform(train_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f33655",
   "metadata": {},
   "source": [
    "### 1. **`make_train_data(data, train_size, predict_size)`**:\n",
    "   - 주어진 시계열 데이터(`data`)로부터 학습용 데이터와 레이블을 생성하는 함수입니다.\n",
    "   - `train_size`: 학습에 사용할 시계열 데이터의 기간\n",
    "   - `predict_size`: 추론에 사용할 시계열 데이터의 기간\n",
    "   - 함수 내부에서는 `data`의 각 행을 순회하며 데이터를 추출합니다.\n",
    "   - 추출한 데이터는 입력 데이터(input_data)와 레이블(target_data)로 구성됩니다.\n",
    "   - `input_data`는 학습 데이터의 윈도우 내에서 판매량과 관련된 피처를 포함합니다. 윈도우 내에서의 판매량 이전에 있는 데이터도 인코딩 정보와 함께 입력 데이터로 사용됩니다.\n",
    "   - `target_data`는 추론할 기간의 판매량을 나타냅니다.\n",
    "\n",
    "### 2. **`make_predict_data(data, train_size)`**:\n",
    "   - 주어진 시계열 데이터(`data`)로부터 추론용 데이터를 생성하는 함수입니다.\n",
    "   - `train_size`: 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "   - 함수 내부에서는 `data`의 각 행을 순회하며 데이터를 추출합니다.\n",
    "   - 추출한 데이터는 추론용 입력 데이터(input_data)로 구성됩니다.\n",
    "   - `input_data`는 추론을 위한 입력 데이터로, 인코딩 정보와 윈도우 내의 판매량을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31875e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 학습에 활용할 기간\n",
    "    predict_size : 추론할 기간\n",
    "    '''\n",
    "  \n",
    "    STEP_SIZE = 5 # 이 값을 본인의 환경에 맞게 조정\n",
    "    \n",
    "    \n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "    adjusted_size = (len(data.columns) - window_size + 1) // STEP_SIZE\n",
    "\n",
    "    input_data = np.empty((num_rows * adjusted_size, train_size, len(data.iloc[0, :4]) + 1))\n",
    "    target_data = np.empty((num_rows * adjusted_size, predict_size))\n",
    "\n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, 4:])\n",
    "\n",
    "        for j in range(0, len(sales_data) - window_size + 1, STEP_SIZE):\n",
    "            window = sales_data[j: j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * adjusted_size + j // STEP_SIZE] = temp_data\n",
    "            target_data[i * adjusted_size + j // STEP_SIZE] = window[train_size:]\n",
    "            \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37cbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']):\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :4]) + 1))\n",
    "    \n",
    "    STEP_SIZE = 5  \n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, -train_size:])\n",
    "        \n",
    "        for j in range(0, len(sales_data) - train_size + 1, STEP_SIZE):\n",
    "            window = sales_data[j : j + train_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window))\n",
    "            input_data[i * (len(sales_data) - train_size + 1) // STEP_SIZE + j // STEP_SIZE] = temp_data\n",
    "    \n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc79d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b52702165714827a5fd7fede9aa50a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1904b3272d1743daa8a4ae7f7d660503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.58224129676819\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_input, train_target = make_train_data(train_data)\n",
    "test_input = make_predict_data(train_data)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec38706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((889840, 90, 5), (889840, 21), (222460, 90, 5), (222460, 21), (15890, 90, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]\n",
    "\n",
    "train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7123d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed21b8b3d6d94209aa7a75157e6b6ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=512, output_size=CFG['PREDICT_SIZE']):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_size//2, output_size)\n",
    "        )\n",
    "            \n",
    "        self.actv = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, TRAIN_WINDOW_SIZE, 5)\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size, x.device)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Only use the last output sequence\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer\n",
    "        output = self.actv(self.fc(last_output))\n",
    "        \n",
    "        return output.squeeze(1)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Initialize hidden state and cell state\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))\n",
    "    \n",
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_mae = []\n",
    "        for X, Y in tqdm(iter(train_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            print('Model Saved')\n",
    "    return best_model\n",
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "model = BaseModel()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
